stage: sft
do_train: true
do_eval: true

# ==== MODEL ====
model_name_or_path: Qwen/Qwen3-8B
template: qwen
finetuning_type: lora

# ==== DATA ====
dataset_dir: data
dataset: movielens_qwen3_train
eval_dataset: movielens_qwen3_eval
cutoff_len: 1024
max_samples: null
max_eval_samples: 100  # Increased from 25 for more reliable eval metrics

# ==== OUTPUT & LOGGING ====
# For training, this is the output directory
# For inference/comparison, use the checkpoint directory that has adapter_config.json
output_dir: output/qwen3-7b-movielens-qlora-2/
logging_steps: 500  # Log metrics including GPU memory every 500 steps
save_steps: 4000
eval_steps: 2000  # Reduced eval frequency (was 10) since eval is more expensive now
eval_accumulation_steps: 2  # Reduced to prevent OOM during eval
save_total_limit: 2
skip_memory_metrics: false  # Enable GPU memory logging to TensorBoard

# ==== BATCHING (24GB-FRIENDLY) ====
# 8B QLoRA with gradient_checkpointing=True can handle bs=2 at seq=1024
# Effective batch size = 2 Ã— 8 = 16
per_device_train_batch_size: 4
per_device_eval_batch_size: 2
gradient_accumulation_steps: 4

# ==== OPTIMIZER / LR ====
learning_rate: 3.0e-4
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.03
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-8
max_grad_norm: 1.0

# ==== LORA ====
lora_target: qv  # Query and value only (skips key, output proj, and MLP)
lora_rank: 16
lora_alpha: 32
lora_dropout: 0.05
use_rslora: false
use_qlora: true

# ==== MEMORY / STABILITY ====
gradient_checkpointing: true  # CRITICAL: Reduces activation memory by ~90%
flash_attn: auto
ddp_timeout: 180000000

# ==== EARLY STOPPING / LOSS PLATEAU ====
early_stopping_patience: 5  # Increased from 3 to allow more training
loss_plateau_patience: 5    # Increased from 3 to allow more training
loss_plateau_min_delta: 0.0001

# ==== PRECISION ====
fp16: false
bf16: true    # keep bf16; works great on 4090-class GPUs
eval_strategy: steps
prediction_loss_only: false

report_to:
  - tensorboard

# ==== INFERENCE & EVALUATION ====
inference:
  test_file: data/movielens_qwen3/test_raw.jsonl  # Path to test data
  # test_file: data/movielens_qwen3/train.json # use traindata for eval
  infer_output_dir: infer_results/  # Directory for inference results (NOT under output_dir)
  batch_size: 8  # Batch size for inference (higher = faster but more memory)
  max_samples: 100  # Limit samples for quick testing (null = use all)
  show_examples: 5  # Number of examples to show in analysis report
