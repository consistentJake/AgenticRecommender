stage: sft
do_train: true
do_eval: true

# ==== MODEL ====
model_name_or_path: Qwen/Qwen3-8B
template: qwen
finetuning_type: lora

# ==== DATA ====
dataset_dir: data
dataset: movielens_qwen3_train
eval_dataset: movielens_qwen3_eval
cutoff_len: 1024
max_samples: null
max_eval_samples: 100  # Increased from 25 for more reliable eval metrics

# ==== OUTPUT & LOGGING ====
output_dir: output/qwen3-7b-movielens-qlora
logging_steps: 10
save_steps: 500
eval_steps: 100  # Reduced eval frequency (was 10) since eval is more expensive now
eval_accumulation_steps: 5
save_total_limit: 2

# ==== BATCHING (24GB-FRIENDLY) ====
# 7B QLoRA fits comfortably on 24GB at seq=1024 with bs=2
# when using gradient checkpointing. :contentReference[oaicite:2]{index=2}
per_device_train_batch_size: 2
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8

# ==== OPTIMIZER / LR ====
learning_rate: 1.0e-4
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.03
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-8
max_grad_norm: 1.0

# ==== LORA ====
lora_target: qv  # Query and value only (skips key, output proj, and MLP)
lora_rank: 16
lora_alpha: 64
lora_dropout: 0.05
use_rslora: false
use_qlora: true

# ==== MEMORY / STABILITY ====
gradient_checkpointing: true
flash_attn: auto
ddp_timeout: 180000000

# ==== EARLY STOPPING / LOSS PLATEAU ====
early_stopping_patience: 5  # Increased from 3 to allow more training
loss_plateau_patience: 5    # Increased from 3 to allow more training
loss_plateau_min_delta: 0.002

# ==== PRECISION ====
fp16: false
bf16: true    # keep bf16; works great on 4090-class GPUs
eval_strategy: steps
prediction_loss_only: false

report_to:
  - tensorboard

# ==== INFERENCE & EVALUATION ====
inference:
  test_file: data/movielens_qwen3/test_raw.jsonl  # Path to test data
  infer_subdir: infer  # Subdirectory under output_dir for inference results
  max_samples: 200  # Limit samples for quick testing (null = use all)
  show_examples: 5  # Number of examples to show in analysis report
