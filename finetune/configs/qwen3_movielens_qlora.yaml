# Optimized config for Qwen3-0.6B MovieLens LoRA (rank=16, 4-bit).
#
# Training follows best practices:
# - Moderate eval frequency (200 steps) to monitor progress
# - Low eval_accumulation_steps (2) to prevent OOM by moving predictions to CPU frequently
# - Batch sizes tuned for 24GB GPU (train=2, eval=1)
# - Sequence length matched to p95 data length (1024)
# - Gradient checkpointing disabled for faster training (if VRAM allows)
# - Metrics: accuracy, F1 score on Yes/No predictions
# - Early stopping to prevent overfitting
#
# Usage:
#   python scripts/finetune_lora.py --config configs/qwen3_movielens_qlora.yaml

stage: sft
do_train: true
do_eval: true
model_name_or_path: Qwen/Qwen3-0.6B
template: qwen
finetuning_type: lora
dataset_dir: data
dataset: movielens_qwen3_train
eval_dataset: movielens_qwen3_eval
cutoff_len: 1024
max_samples: null
max_eval_samples: 25

output_dir: output/qwen3-movielens-qlora
logging_steps: 10
save_steps: 500
eval_steps: 10
eval_accumulation_steps: 1
save_total_limit: 2

per_device_train_batch_size: 2
per_device_eval_batch_size: 1
gradient_accumulation_steps: 8
learning_rate: 1.5e-4
num_train_epochs: 3
lr_scheduler_type: cosine
warmup_ratio: 0.03
weight_decay: 0.0
adam_beta1: 0.9
adam_beta2: 0.999
adam_epsilon: 1.0e-8
max_grad_norm: 1.0

lora_target: fn
lora_rank: 16
lora_alpha: 64
lora_dropout: 0.05
use_rslora: false
use_qlora: true

gradient_checkpointing: false
early_stopping_patience: 3
loss_plateau_patience: 3
loss_plateau_min_delta: 0.002
ddp_timeout: 180000000
flash_attn: auto

eval_strategy: steps
prediction_loss_only: false
fp16: false
bf16: true

report_to:
  - tensorboard

# ==== INFERENCE & EVALUATION ====
inference:
  test_file: data/movielens_qwen3/test_raw.jsonl  # Path to test data
  infer_subdir: infer  # Subdirectory under output_dir for inference results
  max_samples: 200  # Limit samples for quick testing (null = use all)
  show_examples: 5  # Number of examples to show in analysis report
