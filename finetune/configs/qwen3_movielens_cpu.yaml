# CPU-friendly config for Qwen3-0.6B MovieLens LoRA (no quantization)
#
# Usage:
#   python scripts/train_llamafactory.py --config configs/qwen3_movielens_cpu.yaml

stage: sft
do_train: true
do_eval: true
model_name_or_path: Qwen/Qwen3-0.6B
template: qwen
finetuning_type: lora
dataset_dir: data
dataset: movielens_qwen3_train
eval_dataset: movielens_qwen3_eval
cutoff_len: 2048
max_samples: null

output_dir: output/qwen3-movielens-cpu
logging_steps: 10
save_steps: 200
eval_steps: 200
save_total_limit: 2

per_device_train_batch_size: 1
per_device_eval_batch_size: 1
gradient_accumulation_steps: 1
learning_rate: 1.5e-4
num_train_epochs: 1
lr_scheduler_type: cosine
warmup_ratio: 0.03
weight_decay: 0.0
max_grad_norm: 1.0

lora_target: all
lora_rank: 16
lora_alpha: 64
lora_dropout: 0.05
use_rslora: false

gradient_checkpointing: true
ddp_timeout: 180000000
flash_attn: auto

eval_strategy: steps
fp16: false
bf16: false
use_cpu: true

report_to:
  - tensorboard
