# Qwen3 MovieLens LoRA Starter

This repository is a runnable bootstrap for the task described in `docs/task`: fine-tune **Qwen3-0.6B** with **LoRA (rank=16)** using **LLaMA-Factory** on a sequential MovieLens recommendation dataset (last 15 watched movies → Yes/No recommendation). The code covers:

- MovieLens cleanup, sequential example construction, and Alpaca/Qwen3 style prompt formatting.
- Turn-key LLaMA-Factory configuration for 4-bit QLoRA that fits on a **single RTX 4090** yet can also run in CPU-only mode (very slow but useful for smoke tests).
- A before/after evaluation script to quantify gains after fine-tuning.

> All scripts live inside this `finetune/` folder as requested. They do not require editing files elsewhere in the repo.

## Environment

```
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

`llama-factory` pulls in all training dependencies (Transformers, PEFT, bitsandbytes, etc.). CPU-only users should also install `accelerate[cpu]` and skip `bitsandbytes` if compilation fails.

## 1. Prepare MovieLens

```
python scripts/prepare_movielens.py \
  --source /path/to/ml-latest-small \
  --output-dir data/movielens_qwen3 \
  --history-len 15 \
  --rating-threshold 4.0
```

Optional flags: `--download` (auto fetch & unzip MovieLens), `--max-per-user`, `--seed`, `--val-ratio`, `--test-ratio`.  
Artifacts:

- `train.json` / `eval.json`: Alpaca format for LLaMA-Factory.
- `test_raw.jsonl`: raw fields (user id, titles, labels) for Python evaluation.
- `meta.json`: run metadata.

## 2. Launch LLaMA-Factory (CPU or RTX 4090)

Use the provided config (`configs/qwen3_movielens_qlora.yaml`) which already wires:

- Base model: `Qwen/Qwen3-0.6B-Instruct`
- `finetuning_type: lora`, `lora_rank: 16`, `lora_alpha: 64`, `lora_dropout: 0.05`
- 4-bit QLoRA via `quantization_bit: 4`, `quantization_method: bnb`
- `template: qwen` so prompts match the chat format generated by the data prep script.

```
# GPU (RTX 4090 assumed)
python scripts/train_llamafactory.py \
  --config configs/qwen3_movielens_qlora.yaml \
  --run-name qwen3-movielens-qlora

# CPU smoke test (forces CPU + float32 math; expect this to be slow)
python scripts/train_llamafactory.py \
  --config configs/qwen3_movielens_qlora.yaml \
  --run-name cpu-check \
  --device cpu \
  --override per_device_train_batch_size=1 \
  --override gradient_accumulation_steps=1 \
  --override bf16=false \
  --override torch_dtype=float32
```

The trainer writes adapters into `output/qwen3-movielens-qlora/` by default (override with `--output-dir`).

## 3. Evaluate Before/After

```
python scripts/evaluate.py \
  --test-file data/movielens_qwen3/test_raw.jsonl \
  --base-model Qwen/Qwen3-0.6B-Instruct \
  --lora-output output/qwen3-movielens-qlora \
  --device auto \
  --max-samples 300
```

The script loads the base model and LoRA-adapted model (4-bit quantized if CUDA is available, float32 on CPU) and prints accuracies such as:

```
Base model accuracy: 0.41 on 280 samples
Finetuned model accuracy: 0.67 on 280 samples
```

## Repository Layout

```
README.md                         – high-level workflow
requirements.txt                  – Python dependencies
configs/qwen3_movielens_qlora.yaml– LLaMA-Factory config
scripts/prepare_movielens.py      – data cleanup + formatting
scripts/train_llamafactory.py     – thin wrapper around LLaMA-Factory CLI
scripts/evaluate.py               – before/after accuracy scorer
docs/                             – task descriptions provided by the user
```

You can now iterate on prompt wording, LoRA hyperparameters, or swap in a different MovieLens split by editing the scripts/configs in this folder. Feel free to integrate TensorBoard/W&B logging via LLaMA-Factory flags if you need richer monitoring later.
