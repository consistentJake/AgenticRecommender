nohup: ignoring input
`torch_dtype` is deprecated! Use `dtype` instead!
Using device: cuda
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆ        | 1/5 [00:01<00:06,  1.62s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 2/5 [00:03<00:05,  1.92s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [00:05<00:04,  2.00s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 4/5 [00:07<00:01,  1.88s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  1.25s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:07<00:00,  1.53s/it]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151645}.

Loading preprocessed datasets from cache: .cache/preprocessed
Cached datasets loaded successfully!

  0%|          | 0/14676 [00:00<?, ?it/s]/opt/conda/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.
  return fn(*args, **kwargs)
Casting fp32 inputs back to torch.bfloat16 for flash-attn compatibility.
  0%|          | 1/14676 [00:05<20:28:55,  5.02s/it]  0%|          | 2/14676 [00:09<19:54:10,  4.88s/it]  0%|          | 3/14676 [00:14<19:56:06,  4.89s/it]  0%|          | 4/14676 [00:19<19:46:37,  4.85s/it]  0%|          | 5/14676 [00:24<19:42:20,  4.84s/it]  0%|          | 6/14676 [00:29<19:43:51,  4.84s/it]  0%|          | 7/14676 [00:33<19:35:00,  4.81s/it]  0%|          | 8/14676 [00:38<19:39:03,  4.82s/it]  0%|          | 9/14676 [00:43<19:30:53,  4.79s/it]  0%|          | 10/14676 [00:48<19:29:06,  4.78s/it]                                                       0%|          | 10/14676 [00:48<19:29:06,  4.78s/it]  0%|          | 11/14676 [00:53<19:36:51,  4.81s/it]  0%|          | 12/14676 [00:57<19:40:24,  4.83s/it]  0%|          | 13/14676 [01:02<19:41:32,  4.83s/it]  0%|          | 14/14676 [01:07<19:40:53,  4.83s/it]  0%|          | 15/14676 [01:12<19:35:10,  4.81s/it]  0%|          | 16/14676 [01:17<19:39:29,  4.83s/it]  0%|          | 17/14676 [01:22<19:40:50,  4.83s/it]  0%|          | 18/14676 [01:26<19:39:17,  4.83s/it]  0%|          | 19/14676 [01:31<19:41:34,  4.84s/it]  0%|          | 20/14676 [01:36<19:39:22,  4.83s/it]                                                       0%|          | 20/14676 [01:36<19:39:22,  4.83s/it]  0%|          | 21/14676 [01:41<19:40:02,  4.83s/it]  0%|          | 22/14676 [01:46<19:34:49,  4.81s/it]  0%|          | 23/14676 [01:51<19:39:45,  4.83s/it]  0%|          | 24/14676 [01:55<19:40:23,  4.83s/it]  0%|          | 25/14676 [02:00<19:41:13,  4.84s/it]  0%|          | 26/14676 [02:05<19:40:34,  4.84s/it]  0%|          | 27/14676 [02:10<19:39:08,  4.83s/it]  0%|          | 28/14676 [02:15<19:34:30,  4.81s/it]  0%|          | 29/14676 [02:19<19:33:03,  4.81s/it]  0%|          | 30/14676 [02:24<19:30:43,  4.80s/it]                                                       0%|          | 30/14676 [02:24<19:30:43,  4.80s/it]  0%|          | 31/14676 [02:29<19:31:11,  4.80s/it]  0%|          | 32/14676 [02:34<19:30:40,  4.80s/it]  0%|          | 33/14676 [02:39<19:28:22,  4.79s/it]  0%|          | 34/14676 [02:43<19:32:47,  4.81s/it]  0%|          | 35/14676 [02:48<19:29:06,  4.79s/it]  0%|          | 36/14676 [02:53<19:32:07,  4.80s/it]  0%|          | 37/14676 [02:58<19:28:33,  4.79s/it]  0%|          | 38/14676 [03:03<19:26:12,  4.78s/it]  0%|          | 39/14676 [03:07<19:20:50,  4.76s/it]  0%|          | 40/14676 [03:12<19:26:25,  4.78s/it]                                                       0%|          | 40/14676 [03:12<19:26:25,  4.78s/it]  0%|          | 41/14676 [03:17<19:20:08,  4.76s/it]  0%|          | 42/14676 [03:22<19:28:39,  4.79s/it]  0%|          | 43/14676 [03:27<19:35:22,  4.82s/it]  0%|          | 44/14676 [03:31<19:30:38,  4.80s/it]  0%|          | 45/14676 [03:36<19:34:16,  4.82s/it]  0%|          | 46/14676 [03:41<19:37:59,  4.83s/it]  0%|          | 47/14676 [03:46<19:34:37,  4.82s/it]  0%|          | 48/14676 [03:51<19:32:57,  4.81s/it]  0%|          | 49/14676 [03:55<19:36:44,  4.83s/it]  0%|          | 50/14676 [04:00<19:39:19,  4.84s/it]                                                       0%|          | 50/14676 [04:00<19:39:19,  4.84s/it]
[TrainingLossPlateauCallback] Initial loss: 5.3621
{'loss': 5.3621, 'grad_norm': 52.363746643066406, 'learning_rate': 2.040816326530612e-06, 'entropy': 0.5223934397101402, 'num_tokens': 69287.0, 'mean_token_accuracy': 0.5640625, 'epoch': 0.0}

[TrainingLossPlateauCallback] Loss improved by 1.7982 to 3.5639. Resetting patience.
{'loss': 3.5639, 'grad_norm': 22.061079025268555, 'learning_rate': 4.308390022675737e-06, 'entropy': 0.5250922907143831, 'num_tokens': 139015.0, 'mean_token_accuracy': 0.6234375, 'epoch': 0.0}

[TrainingLossPlateauCallback] Loss improved by 1.8271 to 1.7368. Resetting patience.
{'loss': 1.7368, 'grad_norm': 8.993339538574219, 'learning_rate': 6.5759637188208614e-06, 'entropy': 0.525488407164812, 'num_tokens': 208362.0, 'mean_token_accuracy': 0.75546875, 'epoch': 0.01}

[TrainingLossPlateauCallback] Loss improved by 1.1289 to 0.6079. Resetting patience.
{'loss': 0.6079, 'grad_norm': 2.0500545501708984, 'learning_rate': 8.843537414965987e-06, 'entropy': 0.5278388269245624, 'num_tokens': 277786.0, 'mean_token_accuracy': 0.85625, 'epoch': 0.01}

[TrainingLossPlateauCallback] Loss improved by 0.5216 to 0.0863. Resetting patience.
{'loss': 0.0863, 'grad_norm': 0.44918155670166016, 'learning_rate': 1.1111111111111112e-05, 'entropy': 0.524496391415596, 'num_tokens': 347520.0, 'mean_token_accuracy': 0.95078125, 'epoch': 0.01}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:01, 17.16it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:01, 10.84it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:01,  9.72it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:00<00:01,  9.28it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:00<00:01,  9.12it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:01<00:01,  9.01it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:01<00:01,  8.93it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:01<00:01,  8.87it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:01<00:01,  8.79it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:01<00:01,  8.73it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:01<00:01,  8.74it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:01<00:01,  8.66it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:01<00:00,  8.63it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:01<00:00,  8.63it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:02<00:00,  8.65it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:02<00:00,  8.65it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:02<00:00,  8.65it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:02<00:00,  8.65it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:02<00:00,  8.62it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:02<00:00,  8.63it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.62it/s][A                                                     
                                               [A  0%|          | 50/14676 [04:03<19:39:19,  4.84s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.62it/s][A
                                               [A  0%|          | 51/14676 [04:08<23:16:41,  5.73s/it]  0%|          | 52/14676 [04:13<22:01:27,  5.42s/it]  0%|          | 53/14676 [04:18<21:11:18,  5.22s/it]  0%|          | 54/14676 [04:22<20:42:20,  5.10s/it]  0%|          | 55/14676 [04:27<20:19:01,  5.00s/it]  0%|          | 56/14676 [04:32<20:13:48,  4.98s/it]  0%|          | 57/14676 [04:37<19:59:24,  4.92s/it]  0%|          | 58/14676 [04:42<19:49:48,  4.88s/it]  0%|          | 59/14676 [04:46<19:40:09,  4.84s/it]  0%|          | 60/14676 [04:51<19:34:09,  4.82s/it]                                                       0%|          | 60/14676 [04:51<19:34:09,  4.82s/it]  0%|          | 61/14676 [04:56<19:31:17,  4.81s/it]  0%|          | 62/14676 [05:01<19:33:07,  4.82s/it]  0%|          | 63/14676 [05:06<20:13:18,  4.98s/it]  0%|          | 64/14676 [05:11<20:03:30,  4.94s/it]  0%|          | 65/14676 [05:16<19:50:02,  4.89s/it]  0%|          | 66/14676 [05:21<19:41:44,  4.85s/it]  0%|          | 67/14676 [05:25<19:36:40,  4.83s/it]  0%|          | 68/14676 [05:30<19:29:31,  4.80s/it]  0%|          | 69/14676 [05:35<19:28:05,  4.80s/it]  0%|          | 70/14676 [05:40<19:29:33,  4.80s/it]                                                       0%|          | 70/14676 [05:40<19:29:33,  4.80s/it]  0%|          | 71/14676 [05:44<19:25:28,  4.79s/it]  0%|          | 72/14676 [05:49<19:31:13,  4.81s/it]  0%|          | 73/14676 [05:54<19:24:08,  4.78s/it]  1%|          | 74/14676 [05:59<19:25:15,  4.79s/it]  1%|          | 75/14676 [06:04<19:28:11,  4.80s/it]  1%|          | 76/14676 [06:08<19:27:29,  4.80s/it]  1%|          | 77/14676 [06:13<19:29:40,  4.81s/it]  1%|          | 78/14676 [06:18<19:27:40,  4.80s/it]  1%|          | 79/14676 [06:23<19:32:54,  4.82s/it]  1%|          | 80/14676 [06:28<19:27:58,  4.80s/it]                                                       1%|          | 80/14676 [06:28<19:27:58,  4.80s/it]  1%|          | 81/14676 [06:33<19:31:03,  4.81s/it]  1%|          | 82/14676 [06:37<19:27:38,  4.80s/it]  1%|          | 83/14676 [06:42<19:23:19,  4.78s/it]  1%|          | 84/14676 [06:47<19:26:37,  4.80s/it]  1%|          | 85/14676 [06:52<19:27:02,  4.80s/it]  1%|          | 86/14676 [06:57<19:32:19,  4.82s/it]  1%|          | 87/14676 [07:01<19:35:54,  4.84s/it]  1%|          | 88/14676 [07:06<19:31:20,  4.82s/it]  1%|          | 89/14676 [07:11<19:23:18,  4.78s/it]  1%|          | 90/14676 [07:16<19:25:01,  4.79s/it]                                                       1%|          | 90/14676 [07:16<19:25:01,  4.79s/it]  1%|          | 91/14676 [07:21<19:25:06,  4.79s/it]  1%|          | 92/14676 [07:25<19:16:04,  4.76s/it]  1%|          | 93/14676 [07:30<19:13:35,  4.75s/it]  1%|          | 94/14676 [07:35<19:17:22,  4.76s/it]  1%|          | 95/14676 [07:40<19:18:53,  4.77s/it]  1%|          | 96/14676 [07:44<19:22:20,  4.78s/it]  1%|          | 97/14676 [07:49<19:24:44,  4.79s/it]  1%|          | 98/14676 [07:54<19:22:19,  4.78s/it]  1%|          | 99/14676 [07:59<19:19:30,  4.77s/it]  1%|          | 100/14676 [08:03<19:17:00,  4.76s/it]                                                        1%|          | 100/14676 [08:03<19:17:00,  4.76s/it]
=== DEBUG: First 3 eval samples ===

Sample 0:
  Pred text: 

</think>

No


  True text: <think>

</think>

No

  Pred label: 0
  True label: 0

Sample 1:
  Pred text: 

</think>

No


  True text: <think>

</think>

No

  Pred label: 0
  True label: 0

Sample 2:
  Pred text: 

</think>

No


  True text: <think>

</think>

No

  Pred label: 0
  True label: 0

Total valid pairs: 25 / 25
==================================================

{'eval_loss': 0.07948190718889236, 'eval_accuracy': 0.68, 'eval_f1': 0.2, 'eval_runtime': 2.9058, 'eval_samples_per_second': 8.603, 'eval_steps_per_second': 8.603, 'eval_entropy': 0.5518455815315246, 'eval_num_tokens': 347520.0, 'eval_mean_token_accuracy': 0.96, 'epoch': 0.01}

[TrainingLossPlateauCallback] No significant improvement (1/5). Best: 0.0863, Current: 0.0930
{'loss': 0.093, 'grad_norm': 3.4753072261810303, 'learning_rate': 1.3378684807256237e-05, 'entropy': 0.5225029822438956, 'num_tokens': 416791.0, 'mean_token_accuracy': 0.94375, 'epoch': 0.01}

[TrainingLossPlateauCallback] No significant improvement (2/5). Best: 0.0863, Current: 0.0911
{'loss': 0.0911, 'grad_norm': 0.6701774001121521, 'learning_rate': 1.5646258503401362e-05, 'entropy': 0.5255865015089511, 'num_tokens': 486763.0, 'mean_token_accuracy': 0.9390625, 'epoch': 0.01}

[TrainingLossPlateauCallback] Loss improved by 0.0038 to 0.0825. Resetting patience.
{'loss': 0.0825, 'grad_norm': 1.0962247848510742, 'learning_rate': 1.7913832199546487e-05, 'entropy': 0.5326381903141737, 'num_tokens': 556003.0, 'mean_token_accuracy': 0.953125, 'epoch': 0.02}

[TrainingLossPlateauCallback] Loss improved by 0.0060 to 0.0765. Resetting patience.
{'loss': 0.0765, 'grad_norm': 0.5027239918708801, 'learning_rate': 2.018140589569161e-05, 'entropy': 0.5370754670351744, 'num_tokens': 625508.0, 'mean_token_accuracy': 0.95859375, 'epoch': 0.02}

[TrainingLossPlateauCallback] No significant improvement (1/5). Best: 0.0765, Current: 0.0768
{'loss': 0.0768, 'grad_norm': 3.2519285678863525, 'learning_rate': 2.2448979591836737e-05, 'entropy': 0.5275320619344711, 'num_tokens': 694515.0, 'mean_token_accuracy': 0.95703125, 'epoch': 0.02}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:01, 17.30it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:01, 10.96it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:01,  9.81it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:00<00:01,  9.35it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:00<00:01,  9.19it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:01<00:01,  9.07it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:01<00:01,  8.98it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:01<00:01,  8.91it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:01<00:01,  8.83it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:01<00:01,  8.77it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:01<00:01,  8.78it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:01<00:01,  8.74it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:01<00:00,  8.70it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:01<00:00,  8.68it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:02<00:00,  8.70it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:02<00:00,  8.69it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:02<00:00,  8.69it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:02<00:00,  8.68it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:02<00:00,  8.65it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:02<00:00,  8.66it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.65it/s][A                                                      
                                               [A  1%|          | 100/14676 [08:06<19:17:00,  4.76s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.65it/s][A
                                               [A  1%|          | 101/14676 [08:11<22:48:49,  5.63s/it]  1%|          | 102/14676 [08:16<21:39:59,  5.35s/it]  1%|          | 103/14676 [08:21<21:00:40,  5.19s/it]  1%|          | 104/14676 [08:25<20:32:27,  5.07s/it]  1%|          | 105/14676 [08:30<20:14:25,  5.00s/it]  1%|          | 106/14676 [08:35<19:56:18,  4.93s/it]  1%|          | 107/14676 [08:40<19:47:46,  4.89s/it]  1%|          | 108/14676 [08:45<19:47:05,  4.89s/it]  1%|          | 109/14676 [08:49<19:37:22,  4.85s/it]  1%|          | 110/14676 [08:54<19:32:58,  4.83s/it]                                                        1%|          | 110/14676 [08:54<19:32:58,  4.83s/it]  1%|          | 111/14676 [08:59<19:34:22,  4.84s/it]  1%|          | 112/14676 [09:04<19:30:08,  4.82s/it]  1%|          | 113/14676 [09:09<19:30:40,  4.82s/it]  1%|          | 114/14676 [09:13<19:31:00,  4.82s/it]  1%|          | 115/14676 [09:18<19:30:42,  4.82s/it]  1%|          | 116/14676 [09:23<19:28:57,  4.82s/it]  1%|          | 117/14676 [09:28<19:34:16,  4.84s/it]  1%|          | 118/14676 [09:33<19:30:12,  4.82s/it]  1%|          | 119/14676 [09:38<19:26:24,  4.81s/it]  1%|          | 120/14676 [09:42<19:21:05,  4.79s/it]                                                        1%|          | 120/14676 [09:42<19:21:05,  4.79s/it]  1%|          | 121/14676 [09:47<19:09:13,  4.74s/it]  1%|          | 122/14676 [09:52<19:15:29,  4.76s/it]  1%|          | 123/14676 [09:57<19:20:17,  4.78s/it]  1%|          | 124/14676 [10:01<19:23:21,  4.80s/it]  1%|          | 125/14676 [10:06<19:23:10,  4.80s/it]  1%|          | 126/14676 [10:11<19:25:43,  4.81s/it]  1%|          | 127/14676 [10:16<19:25:27,  4.81s/it]  1%|          | 128/14676 [10:21<19:25:27,  4.81s/it]  1%|          | 129/14676 [10:25<19:22:01,  4.79s/it]  1%|          | 130/14676 [10:30<19:21:26,  4.79s/it]                                                        1%|          | 130/14676 [10:30<19:21:26,  4.79s/it]  1%|          | 131/14676 [10:35<19:23:51,  4.80s/it]  1%|          | 132/14676 [10:40<19:18:55,  4.78s/it]  1%|          | 133/14676 [10:45<19:20:59,  4.79s/it]  1%|          | 134/14676 [10:49<19:17:56,  4.78s/it]  1%|          | 135/14676 [10:54<19:21:36,  4.79s/it]  1%|          | 136/14676 [10:59<19:15:11,  4.77s/it]  1%|          | 137/14676 [11:04<19:23:11,  4.80s/it]  1%|          | 138/14676 [11:09<19:30:04,  4.83s/it]  1%|          | 139/14676 [11:14<19:35:09,  4.85s/it]  1%|          | 140/14676 [11:18<19:29:30,  4.83s/it]                                                        1%|          | 140/14676 [11:18<19:29:30,  4.83s/it]  1%|          | 141/14676 [11:23<19:32:33,  4.84s/it]  1%|          | 142/14676 [11:28<19:33:40,  4.85s/it]  1%|          | 143/14676 [11:33<19:23:51,  4.81s/it]  1%|          | 144/14676 [11:37<19:18:10,  4.78s/it]  1%|          | 145/14676 [11:42<19:14:47,  4.77s/it]  1%|          | 146/14676 [11:47<19:19:37,  4.79s/it]  1%|          | 147/14676 [11:52<19:12:55,  4.76s/it]  1%|          | 148/14676 [11:56<19:09:47,  4.75s/it]  1%|          | 149/14676 [12:01<19:11:29,  4.76s/it]  1%|          | 150/14676 [12:06<19:06:52,  4.74s/it]                                                        1%|          | 150/14676 [12:06<19:06:52,  4.74s/it]{'eval_loss': 0.07159402966499329, 'eval_accuracy': 0.72, 'eval_f1': 0.6956521739130435, 'eval_runtime': 2.8889, 'eval_samples_per_second': 8.654, 'eval_steps_per_second': 8.654, 'eval_entropy': 0.5632479894161224, 'eval_num_tokens': 694515.0, 'eval_mean_token_accuracy': 0.965, 'epoch': 0.02}

[TrainingLossPlateauCallback] No significant improvement (2/5). Best: 0.0765, Current: 0.0761
{'loss': 0.0761, 'grad_norm': 0.23385150730609894, 'learning_rate': 2.4716553287981862e-05, 'entropy': 0.5394373249262572, 'num_tokens': 763715.0, 'mean_token_accuracy': 0.9625, 'epoch': 0.02}

[TrainingLossPlateauCallback] Loss improved by 0.0079 to 0.0686. Resetting patience.
{'loss': 0.0686, 'grad_norm': 1.3617732524871826, 'learning_rate': 2.6984126984126984e-05, 'entropy': 0.5347409129142762, 'num_tokens': 832962.0, 'mean_token_accuracy': 0.9671875, 'epoch': 0.02}

[TrainingLossPlateauCallback] No significant improvement (1/5). Best: 0.0686, Current: 0.0739
{'loss': 0.0739, 'grad_norm': 0.43765562772750854, 'learning_rate': 2.925170068027211e-05, 'entropy': 0.5339400187134743, 'num_tokens': 902496.0, 'mean_token_accuracy': 0.9625, 'epoch': 0.03}

[TrainingLossPlateauCallback] No significant improvement (2/5). Best: 0.0686, Current: 0.0752
{'loss': 0.0752, 'grad_norm': 0.6890131235122681, 'learning_rate': 3.151927437641724e-05, 'entropy': 0.5468193594366312, 'num_tokens': 971961.0, 'mean_token_accuracy': 0.95546875, 'epoch': 0.03}

[TrainingLossPlateauCallback] Loss improved by 0.0029 to 0.0657. Resetting patience.
{'loss': 0.0657, 'grad_norm': 2.1234140396118164, 'learning_rate': 3.378684807256236e-05, 'entropy': 0.5422033168375492, 'num_tokens': 1040964.0, 'mean_token_accuracy': 0.96796875, 'epoch': 0.03}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:01, 17.26it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:01, 10.93it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:01,  9.77it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:00<00:01,  9.32it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:00<00:01,  9.16it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:01<00:01,  9.04it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:01<00:01,  8.94it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:01<00:01,  8.88it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:01<00:01,  8.80it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:01<00:01,  8.73it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:01<00:01,  8.74it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:01<00:01,  8.71it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:01<00:00,  8.67it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:01<00:00,  8.65it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:02<00:00,  8.61it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:02<00:00,  8.62it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:02<00:00,  8.63it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:02<00:00,  8.63it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:02<00:00,  8.61it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:02<00:00,  8.62it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.62it/s][A                                                      
                                               [A  1%|          | 150/14676 [12:09<19:06:52,  4.74s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.62it/s][A
                                               [A  1%|          | 151/14676 [12:14<22:36:03,  5.60s/it]  1%|          | 152/14676 [12:18<21:34:28,  5.35s/it]  1%|          | 153/14676 [12:23<20:55:56,  5.19s/it]  1%|          | 154/14676 [12:28<20:29:04,  5.08s/it]  1%|          | 155/14676 [12:33<20:05:46,  4.98s/it]  1%|          | 156/14676 [12:37<19:48:16,  4.91s/it]  1%|          | 157/14676 [12:42<19:37:06,  4.86s/it]  1%|          | 158/14676 [12:47<19:35:23,  4.86s/it]  1%|          | 159/14676 [12:52<19:25:11,  4.82s/it]  1%|          | 160/14676 [12:57<19:22:37,  4.81s/it]                                                        1%|          | 160/14676 [12:57<19:22:37,  4.81s/it]  1%|          | 161/14676 [13:01<19:23:51,  4.81s/it]  1%|          | 162/14676 [13:06<19:23:50,  4.81s/it]  1%|          | 163/14676 [13:11<19:27:19,  4.83s/it]  1%|          | 164/14676 [13:16<19:24:28,  4.81s/it]  1%|          | 165/14676 [13:21<19:20:58,  4.80s/it]  1%|          | 166/14676 [13:25<19:22:42,  4.81s/it]  1%|          | 167/14676 [13:30<19:15:57,  4.78s/it]  1%|          | 168/14676 [13:35<19:12:53,  4.77s/it]  1%|          | 169/14676 [13:40<19:17:06,  4.79s/it]  1%|          | 170/14676 [13:45<19:21:14,  4.80s/it]                                                        1%|          | 170/14676 [13:45<19:21:14,  4.80s/it]  1%|          | 171/14676 [13:49<19:21:47,  4.81s/it]  1%|          | 172/14676 [13:54<19:18:18,  4.79s/it]  1%|          | 173/14676 [13:59<19:16:54,  4.79s/it]  1%|          | 174/14676 [14:04<19:12:54,  4.77s/it]  1%|          | 175/14676 [14:08<19:10:02,  4.76s/it]  1%|          | 176/14676 [14:13<19:19:41,  4.80s/it]  1%|          | 177/14676 [14:18<19:29:56,  4.84s/it]  1%|          | 178/14676 [14:23<19:26:51,  4.83s/it]  1%|          | 179/14676 [14:28<19:26:34,  4.83s/it]  1%|          | 180/14676 [14:33<19:26:22,  4.83s/it]                                                        1%|          | 180/14676 [14:33<19:26:22,  4.83s/it]  1%|          | 181/14676 [14:37<19:19:05,  4.80s/it]  1%|          | 182/14676 [14:42<19:17:31,  4.79s/it]  1%|          | 183/14676 [14:47<19:16:57,  4.79s/it]  1%|â–         | 184/14676 [14:52<19:25:33,  4.83s/it]  1%|â–         | 185/14676 [14:57<19:19:28,  4.80s/it]  1%|â–         | 186/14676 [15:01<19:24:39,  4.82s/it]  1%|â–         | 187/14676 [15:06<19:19:43,  4.80s/it]  1%|â–         | 188/14676 [15:11<19:12:33,  4.77s/it]  1%|â–         | 189/14676 [15:16<19:10:57,  4.77s/it]  1%|â–         | 190/14676 [15:20<19:10:42,  4.77s/it]                                                        1%|â–         | 190/14676 [15:20<19:10:42,  4.77s/it]  1%|â–         | 191/14676 [15:25<19:09:37,  4.76s/it]  1%|â–         | 192/14676 [15:30<19:11:31,  4.77s/it]  1%|â–         | 193/14676 [15:35<19:15:47,  4.79s/it]  1%|â–         | 194/14676 [15:40<19:19:10,  4.80s/it]  1%|â–         | 195/14676 [15:44<19:17:45,  4.80s/it]  1%|â–         | 196/14676 [15:49<19:17:05,  4.79s/it]  1%|â–         | 197/14676 [15:54<19:24:00,  4.82s/it]  1%|â–         | 198/14676 [15:59<19:29:39,  4.85s/it]  1%|â–         | 199/14676 [16:04<19:29:01,  4.85s/it]  1%|â–         | 200/14676 [16:09<19:30:43,  4.85s/it]                                                        1%|â–         | 200/14676 [16:09<19:30:43,  4.85s/it]{'eval_loss': 0.05743573606014252, 'eval_accuracy': 0.84, 'eval_f1': 0.7142857142857143, 'eval_runtime': 2.902, 'eval_samples_per_second': 8.615, 'eval_steps_per_second': 8.615, 'eval_entropy': 0.57444531083107, 'eval_num_tokens': 1040964.0, 'eval_mean_token_accuracy': 0.98, 'epoch': 0.03}

[TrainingLossPlateauCallback] No significant improvement (1/5). Best: 0.0657, Current: 0.0672
{'loss': 0.0672, 'grad_norm': 0.8465272784233093, 'learning_rate': 3.605442176870749e-05, 'entropy': 0.5447085928171873, 'num_tokens': 1110104.0, 'mean_token_accuracy': 0.96640625, 'epoch': 0.03}

[TrainingLossPlateauCallback] Loss improved by 0.0068 to 0.0589. Resetting patience.
{'loss': 0.0589, 'grad_norm': 0.5166460275650024, 'learning_rate': 3.832199546485261e-05, 'entropy': 0.551060451939702, 'num_tokens': 1179594.0, 'mean_token_accuracy': 0.96796875, 'epoch': 0.03}

[TrainingLossPlateauCallback] No significant improvement (1/5). Best: 0.0589, Current: 0.0761
{'loss': 0.0761, 'grad_norm': 0.28662553429603577, 'learning_rate': 4.058956916099774e-05, 'entropy': 0.5618127398192883, 'num_tokens': 1249145.0, 'mean_token_accuracy': 0.9609375, 'epoch': 0.04}

[TrainingLossPlateauCallback] No significant improvement (2/5). Best: 0.0589, Current: 0.0756
{'loss': 0.0756, 'grad_norm': 0.581337034702301, 'learning_rate': 4.2857142857142856e-05, 'entropy': 0.5578962087631225, 'num_tokens': 1318502.0, 'mean_token_accuracy': 0.95234375, 'epoch': 0.04}

[TrainingLossPlateauCallback] No significant improvement (3/5). Best: 0.0589, Current: 0.0810
{'loss': 0.081, 'grad_norm': 0.18071311712265015, 'learning_rate': 4.512471655328798e-05, 'entropy': 0.5569161757826805, 'num_tokens': 1388238.0, 'mean_token_accuracy': 0.9609375, 'epoch': 0.04}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:00<00:01, 17.24it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:00<00:01, 10.92it/s][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:00<00:01,  9.76it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:00<00:01,  9.31it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:00<00:01,  9.15it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:01<00:01,  9.04it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:01<00:01,  8.95it/s][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:01<00:01,  8.89it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:01<00:01,  8.81it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:01<00:01,  8.75it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:01<00:01,  8.76it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:01<00:01,  8.73it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:01<00:00,  8.69it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:01<00:00,  8.67it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:02<00:00,  8.69it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:02<00:00,  8.69it/s][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:02<00:00,  8.69it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:02<00:00,  8.68it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:02<00:00,  8.65it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:02<00:00,  8.65it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.65it/s][A                                                      
                                               [A  1%|â–         | 200/14676 [16:12<19:30:43,  4.85s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:02<00:00,  8.65it/s][A
                                               [A  1%|â–         | 201/14676 [16:16<23:01:14,  5.73s/it]  1%|â–         | 202/14676 [16:21<21:52:56,  5.44s/it]  1%|â–         | 203/14676 [16:26<21:02:46,  5.24s/it]  1%|â–         | 204/14676 [16:31<20:28:02,  5.09s/it]  1%|â–         | 205/14676 [16:36<20:16:41,  5.04s/it]  1%|â–         | 206/14676 [16:40<19:58:45,  4.97s/it]  1%|â–         | 207/14676 [16:45<19:44:50,  4.91s/it]  1%|â–         | 208/14676 [16:50<19:32:28,  4.86s/it]  1%|â–         | 209/14676 [16:55<19:25:40,  4.83s/it]  1%|â–         | 210/14676 [17:00<19:27:21,  4.84s/it]                                                        1%|â–         | 210/14676 [17:00<19:27:21,  4.84s/it]  1%|â–         | 211/14676 [17:04<19:19:19,  4.81s/it]  1%|â–         | 212/14676 [17:09<19:17:05,  4.80s/it]  1%|â–         | 213/14676 [17:14<19:15:29,  4.79s/it]  1%|â–         | 214/14676 [17:19<19:16:09,  4.80s/it]  1%|â–         | 215/14676 [17:23<19:12:38,  4.78s/it]  1%|â–         | 216/14676 [17:28<19:22:06,  4.82s/it]  1%|â–         | 217/14676 [17:33<19:15:37,  4.80s/it]  1%|â–         | 218/14676 [17:38<19:17:34,  4.80s/it]  1%|â–         | 219/14676 [17:43<19:22:47,  4.83s/it]  1%|â–         | 220/14676 [17:48<19:12:45,  4.78s/it]                                                        1%|â–         | 220/14676 [17:48<19:12:45,  4.78s/it]                                                        1%|â–         | 220/14676 [17:48<19:12:45,  4.78s/it]  1%|â–         | 220/14676 [17:48<19:29:38,  4.85s/it]
{'eval_loss': 0.06696484237909317, 'eval_accuracy': 0.88, 'eval_f1': 0.8235294117647058, 'eval_runtime': 2.8981, 'eval_samples_per_second': 8.626, 'eval_steps_per_second': 8.626, 'eval_entropy': 0.5939331364631653, 'eval_num_tokens': 1388238.0, 'eval_mean_token_accuracy': 0.985, 'epoch': 0.04}

[TrainingLossPlateauCallback] No significant improvement (4/5). Best: 0.0589, Current: 0.0753
{'loss': 0.0753, 'grad_norm': 0.34583255648612976, 'learning_rate': 4.7392290249433106e-05, 'entropy': 0.5677304197102785, 'num_tokens': 1457821.0, 'mean_token_accuracy': 0.9609375, 'epoch': 0.04}

[TrainingLossPlateauCallback] No significant improvement (5/5). Best: 0.0589, Current: 0.0764

[TrainingLossPlateauCallback] Training loss plateaued. Stopping training.
{'loss': 0.0764, 'grad_norm': 0.295703649520874, 'learning_rate': 4.965986394557823e-05, 'entropy': 0.5561441715806723, 'num_tokens': 1527170.0, 'mean_token_accuracy': 0.96015625, 'epoch': 0.04}
{'train_runtime': 1068.0253, 'train_samples_per_second': 219.857, 'train_steps_per_second': 13.741, 'train_loss': 0.5748417101123117, 'epoch': 0.04}
Training complete. Adapter + tokenizer saved to: output/qwen3-movielens-qlora
