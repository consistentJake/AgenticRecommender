{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "796eeba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset paths:\n",
      "  Reviews: /home/zhenkai/personal/Projects/AgenticRecommender/agentic_recommender/data/inputs/reviews_Beauty.json\n",
      "  Metadata: /home/zhenkai/personal/Projects/AgenticRecommender/agentic_recommender/data/inputs/meta_Beauty.json\n",
      "\n",
      "üìä Testing data loading...\n",
      "üîç Applying 5-core filtering...\n",
      "  Iteration 1: 313823 interactions\n",
      "  Iteration 2: 224229 interactions\n",
      "  Iteration 3: 205760 interactions\n",
      "  Iteration 4: 200771 interactions\n",
      "  Iteration 5: 199277 interactions\n",
      "  Iteration 6: 198741 interactions\n",
      "  Iteration 7: 198554 interactions\n",
      "  Iteration 8: 198506 interactions\n",
      "  Iteration 9: 198502 interactions\n",
      "  Iteration 10: 198502 interactions\n",
      "‚úÖ 5-core filtering completed after 10 iterations\n",
      "‚úÖ Raw data loaded: 198502 interactions\n",
      "‚úÖ Metadata processed: 258760 items have names\n",
      "\n",
      "üè∑Ô∏è Sample item names:\n",
      "  0205616461: Bio-Active Anti-Aging Serum (Firming Ultra-Hydrating Serum)\n",
      "  0558925278: Eco Friendly Ecotools Quality Natural Bamboo Cosmetic Mineral Brush Set Kit of 4 Soft Brushes and...\n",
      "  0733001998: Mastiha Body Lotion\n",
      "\n",
      "üéâ Dataset loading successful! Real Amazon Beauty data is working.\n"
     ]
    }
   ],
   "source": [
    "# Test the Beauty dataset with real data\n",
    "import sys\n",
    "sys.path.insert(0, '/home/zhenkai/personal/Projects/AgenticRecommender')\n",
    "\n",
    "from agentic_recommender.datasets import BeautyDataset\n",
    "\n",
    "# Create dataset instance\n",
    "dataset = BeautyDataset()\n",
    "print(f\"Dataset paths:\")\n",
    "print(f\"  Reviews: {dataset.data_path}\")\n",
    "print(f\"  Metadata: {dataset.metadata_path}\")\n",
    "\n",
    "print(\"\\nüìä Testing data loading...\")\n",
    "try:\n",
    "    # Test raw data loading\n",
    "    raw_data = dataset._load_raw_data()\n",
    "    print(f\"‚úÖ Raw data loaded: {len(raw_data)} interactions\")\n",
    "    \n",
    "    # Test metadata processing\n",
    "    metadata = dataset._process_metadata()\n",
    "    print(f\"‚úÖ Metadata processed: {len(metadata)} items have names\")\n",
    "    \n",
    "    # Show a few examples\n",
    "    sample_items = list(metadata.items())[:3]\n",
    "    print(f\"\\nüè∑Ô∏è Sample item names:\")\n",
    "    for item_id, name in sample_items:\n",
    "        print(f\"  {item_id}: {name}\")\n",
    "    \n",
    "    print(\"\\nüéâ Dataset loading successful! Real Amazon Beauty data is working.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3955ca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Exploring Input JSON Files\n",
      "\n",
      "üìä REVIEWS DATA:\n",
      "\n",
      "Review 1:\n",
      "  reviewerID: A39HTATAQ9V7YF\n",
      "  asin: 0205616461\n",
      "  reviewerName: cheryl roberts\n",
      "  helpful: [0, 0]\n",
      "  reviewText: i do love this moisturizer and would recommend it to someone for dry skin ,fine ...\n",
      "  overall: 5.0\n",
      "  ... and 3 more fields\n",
      "\n",
      "Review 2:\n",
      "  reviewerID: A3JM6GV9MNOF9X\n",
      "  asin: 0558925278\n",
      "  reviewerName: Patty\n",
      "  helpful: [0, 1]\n",
      "  reviewText: I received this product before the deadline.I tested only Baby Kabuki, and the q...\n",
      "  overall: 3.0\n",
      "  ... and 3 more fields\n",
      "\n",
      "Review 3:\n",
      "  reviewerID: A1Z513UWSAAO0F\n",
      "  asin: 0558925278\n",
      "  reviewerName: Renita M\n",
      "  helpful: [0, 0]\n",
      "  reviewText: I love this set. Great buy for the price. I don't wear makeup all the time, but ...\n",
      "  overall: 5.0\n",
      "  ... and 3 more fields\n",
      "\n",
      "Review 4:\n",
      "  reviewerID: A1WMRR494NWEWV\n",
      "  asin: 0733001998\n",
      "  reviewerName: Amazon Shopper\n",
      "  helpful: [0, 0]\n",
      "  reviewText: A nice moisturizer, all natural ingredients and no parabens. A bit pricey, but y...\n",
      "  overall: 4.0\n",
      "  ... and 3 more fields\n",
      "\n",
      "Review 5:\n",
      "  reviewerID: A3IAAVS479H7M7\n",
      "  asin: 0737104473\n",
      "  reviewerName: MAC Lover\n",
      "  helpful: [2, 2]\n",
      "  reviewText: Please research the MAC Hello Kitty collection to determine what the line actual...\n",
      "  overall: 1.0\n",
      "  ... and 3 more fields\n",
      "\n",
      "üìà Total reviews processed: 5 (sample)\n",
      "\n",
      "============================================================\n",
      "üè∑Ô∏è METADATA:\n",
      "\n",
      "Product 1:\n",
      "  asin: 0205616461\n",
      "  description: As we age, our once youthful, healthy skin succumbs to an enzymatic imbalance th...\n",
      "  title: Bio-Active Anti-Aging Serum (Firming Ultra-Hydrating Serum)\n",
      "  imUrl: http://ecx.images-amazon.com/images/I/41DecrGODDL._SY300_.jpg\n",
      "  salesRank: dict with 1 keys\n",
      "  categories: [['Beauty', 'Skin Care', 'Face', 'Creams & Moisturizers']]\n",
      "\n",
      "Product 2:\n",
      "  asin: 0558925278\n",
      "  description: Mineral Powder Brush--Apply powder or mineral foundation all over face in a circ...\n",
      "  title: Eco Friendly Ecotools Quality Natural Bamboo Cosmetic Mineral Brush Set Kit of 4...\n",
      "  imUrl: http://ecx.images-amazon.com/images/I/51L%2BzYCQWSL._SX300_.jpg\n",
      "  salesRank: dict with 1 keys\n",
      "  categories: [['Beauty', 'Tools & Accessories', 'Makeup Brushes & Tools', 'Brushes & Applicators']]\n",
      "\n",
      "Product 3:\n",
      "  asin: 0733001998\n",
      "  description: From the Greek island of Chios, this Mastiha body lotion is made from Mastic oil...\n",
      "  title: Mastiha Body Lotion\n",
      "  imUrl: http://ecx.images-amazon.com/images/I/311WK5y1dML._SY300_.jpg\n",
      "  salesRank: dict with 1 keys\n",
      "  categories: [['Beauty', 'Skin Care', 'Body', 'Moisturizers', 'Lotions']]\n",
      "\n",
      "üìà Total metadata processed: 3 (sample)\n"
     ]
    }
   ],
   "source": [
    "# Explore Input JSON Files (Raw Amazon Beauty Data)\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "print(\"üîç Exploring Input JSON Files\\n\")\n",
    "\n",
    "# Load and explore reviews data\n",
    "reviews_path = '/home/zhenkai/personal/Projects/AgenticRecommender/agentic_recommender/data/inputs/reviews_Beauty.json'\n",
    "meta_path = '/home/zhenkai/personal/Projects/AgenticRecommender/agentic_recommender/data/inputs/meta_Beauty.json'\n",
    "\n",
    "print(\"üìä REVIEWS DATA:\")\n",
    "reviews = []\n",
    "with open(reviews_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 5:  # Only show first 5 for exploration\n",
    "            break\n",
    "        review = json.loads(line.strip())\n",
    "        reviews.append(review)\n",
    "\n",
    "# Display sample reviews\n",
    "for i, review in enumerate(reviews):\n",
    "    print(f\"\\nReview {i+1}:\")\n",
    "    for key, value in list(review.items())[:6]:  # Show first 6 fields\n",
    "        if isinstance(value, str) and len(value) > 80:\n",
    "            value = value[:80] + \"...\"\n",
    "        print(f\"  {key}: {value}\")\n",
    "    if len(review) > 6:\n",
    "        print(f\"  ... and {len(review)-6} more fields\")\n",
    "\n",
    "print(f\"\\nüìà Total reviews processed: {i+1} (sample)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üè∑Ô∏è METADATA:\")\n",
    "metadata = []\n",
    "with open(meta_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:  # Only show first 3 for exploration  \n",
    "            break\n",
    "        try:\n",
    "            # Handle Python dict format\n",
    "            meta = eval(line.strip(), {\"__builtins__\": {}}, {})\n",
    "            metadata.append(meta)\n",
    "        except:\n",
    "            print(f\"Could not parse line {i+1}\")\n",
    "            continue\n",
    "\n",
    "# Display sample metadata\n",
    "for i, meta in enumerate(metadata):\n",
    "    print(f\"\\nProduct {i+1}:\")\n",
    "    for key, value in list(meta.items())[:6]:  # Show first 6 fields\n",
    "        if isinstance(value, str) and len(value) > 80:\n",
    "            value = value[:80] + \"...\"\n",
    "        elif isinstance(value, list) and len(value) > 2:\n",
    "            value = f\"[{len(value)} items: {value[:2]}...]\"\n",
    "        elif isinstance(value, dict):\n",
    "            value = f\"dict with {len(value)} keys\"\n",
    "        print(f\"  {key}: {value}\")\n",
    "    if len(meta) > 6:\n",
    "        print(f\"  ... and {len(meta)-6} more fields\")\n",
    "\n",
    "print(f\"\\nüìà Total metadata processed: {i+1} (sample)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rcq5jg3fsao",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Exploring Output Files (Processed Dataset)\n",
      "\n",
      "üìä DATASET STATISTICS:\n",
      "  num_sessions: 22,363\n",
      "  num_items: 12,101\n",
      "  num_users: 22,363\n",
      "  total_interactions: 198,502\n",
      "  avg_session_length: 8.8764\n",
      "  min_session_length: 5\n",
      "  max_session_length: 204\n",
      "  density: 0.0007\n",
      "\n",
      "============================================================\n",
      "üèÜ EVALUATION SAMPLES:\n",
      "Total evaluation samples: 10\n",
      "\n",
      "Sample evaluation task:\n",
      "Session ID: 10948\n",
      "User ID: A2UIAW0X0S94HL\n",
      "Prompt items (4): ['B004O3UE46', 'B000052ZB4', 'B001DOA73C']...\n",
      "Target item: B002WEBTPW\n",
      "Candidates pool size: 100\n",
      "Target position in candidates: 78\n",
      "\n",
      "üè∑Ô∏è Item names in this session:\n",
      "  B004O3UE46: Almay One Coat Get Up and Grow Waterproof Mascara, Black Brown, 0.21 Fluid Ounce\n",
      "  B000052ZB4: Neutrogena Deep Clean Facial Cleanser, Normal to Oily Skin, 6.7 Ounce\n",
      "  B001DOA73C: L'Oreal Paris True Match Naturale Mineral Foundation, Cocoa, 0.35 Ounce\n",
      "  B0019QQ13Y: e.l.f. Liquid Eyeliner (Plum) elf\n",
      "  B002WEBTPW: 13 Piece Brush Set With Case\n",
      "\n",
      "============================================================\n",
      "üìà SPLIT SIZES:\n",
      "  train: 17,890 sessions\n",
      "  val: 2,236 sessions\n",
      "  test: 2,237 sessions\n",
      "\n",
      "============================================================\n",
      "üî§ ITEM MAPPINGS:\n",
      "Total items with names: 258,760\n",
      "\n",
      "Sample item mappings:\n",
      "  0205616461: Bio-Active Anti-Aging Serum (Firming Ultra-Hydrating Serum)\n",
      "  0558925278: Eco Friendly Ecotools Quality Natural Bamboo Cosmetic Mineral Brush Set Kit of 4 Soft Brushes and...\n",
      "  0733001998: Mastiha Body Lotion\n",
      "  0737104473: Hello Kitty Lustre Lipstick (See sellers comments for colors)\n",
      "  0762451459: Stephanie Johnson Mermaid Round Snap Mirror\n"
     ]
    }
   ],
   "source": [
    "# Explore Output Files (Processed Dataset)\n",
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"üéØ Exploring Output Files (Processed Dataset)\\n\")\n",
    "\n",
    "outputs_dir = Path('/home/zhenkai/personal/Projects/AgenticRecommender/agentic_recommender/data/outputs')\n",
    "\n",
    "# Load dataset statistics\n",
    "print(\"üìä DATASET STATISTICS:\")\n",
    "with open(outputs_dir / 'beauty_stats.json', 'r') as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value:,}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üèÜ EVALUATION SAMPLES:\")\n",
    "\n",
    "# Load evaluation samples\n",
    "with open(outputs_dir / 'beauty_evaluation_samples.json', 'r') as f:\n",
    "    eval_samples = json.load(f)\n",
    "\n",
    "print(f\"Total evaluation samples: {len(eval_samples)}\")\n",
    "print(f\"\\nSample evaluation task:\")\n",
    "\n",
    "sample = eval_samples[0]\n",
    "print(f\"Session ID: {sample['session_id']}\")\n",
    "print(f\"User ID: {sample['user_id']}\")\n",
    "print(f\"Prompt items ({len(sample['prompt_items'])}): {sample['prompt_items'][:3]}...\")\n",
    "print(f\"Target item: {sample['target_item']}\")\n",
    "print(f\"Candidates pool size: {len(sample['candidates'])}\")\n",
    "print(f\"Target position in candidates: {sample['target_index']}\")\n",
    "\n",
    "print(f\"\\nüè∑Ô∏è Item names in this session:\")\n",
    "for item_id, name in list(sample['item_names'].items())[:5]:\n",
    "    print(f\"  {item_id}: {name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìà SPLIT SIZES:\")\n",
    "\n",
    "for split in ['train', 'val', 'test']:\n",
    "    with open(outputs_dir / f'beauty_{split}.json', 'r') as f:\n",
    "        split_data = json.load(f)\n",
    "    print(f\"  {split}: {len(split_data):,} sessions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî§ ITEM MAPPINGS:\")\n",
    "\n",
    "# Load item mappings\n",
    "with open(outputs_dir / 'beauty_item_to_name.json', 'r') as f:\n",
    "    item_to_name = json.load(f)\n",
    "\n",
    "print(f\"Total items with names: {len(item_to_name):,}\")\n",
    "print(f\"\\nSample item mappings:\")\n",
    "sample_items = list(item_to_name.items())[:5]\n",
    "for item_id, name in sample_items:\n",
    "    print(f\"  {item_id}: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ey0z3sp6fwb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä INTERACTIVE DATA ANALYSIS\n",
      "\n",
      "üîç Session Length Distribution:\n",
      "Min length: 5\n",
      "Max length: 204\n",
      "Average length: 8.88\n",
      "Median length: 6.00\n",
      "\n",
      "Most common session lengths:\n",
      "  5 items: 7,162 sessions (32.0%)\n",
      "  6 items: 4,221 sessions (18.9%)\n",
      "  7 items: 2,680 sessions (12.0%)\n",
      "  8 items: 1,811 sessions (8.1%)\n",
      "  9 items: 1,366 sessions (6.1%)\n",
      "  10 items: 881 sessions (3.9%)\n",
      "  11 items: 695 sessions (3.1%)\n",
      "  12 items: 558 sessions (2.5%)\n",
      "  13 items: 439 sessions (2.0%)\n",
      "  14 items: 361 sessions (1.6%)\n",
      "\n",
      "============================================================\n",
      "üè∑Ô∏è Product Category Analysis:\n",
      "Most common beauty product types:\n",
      "  toilette: 194 products\n",
      "  cream: 31 products\n",
      "  lotion: 26 products\n",
      "  oil: 14 products\n",
      "  shampoo,: 13 products\n",
      "  lotion,: 13 products\n",
      "  cleanser,: 13 products\n",
      "  conditioner,: 11 products\n",
      "  cream,: 10 products\n",
      "  shampoo: 9 products\n",
      "\n",
      "============================================================\n",
      "üéØ Recommendation Task Preview:\n",
      "User session example:\n",
      "  User ID: A10CRH1O1H6RSV\n",
      "  Total items in session: 5\n",
      "  Items for prediction context: 4\n",
      "  Target item to predict: B0002FCD5I\n",
      "\n",
      "üìù Context items (what user has purchased):\n",
      "  1. M By Mariah Carey Eau De Parfum Spray, 1-Ounce\n",
      "  2. NYX Single Eye Shadow, Dark Brown, 2.5 g\n",
      "  3. Revlon ColorBurst Lipstick, Baby Pink, 0.13 Fluid Ounces\n",
      "  4. NYX Mechanical Lip Pencil, Nectar\n",
      "\n",
      "üéØ Prediction target:\n",
      "  Suave Naturals Conditioner, Tropical Coconut - 22.5oz.\n",
      "\n",
      "üîÄ Candidate pool:\n",
      "  Total candidates: 100\n",
      "  Target is at position: 98\n",
      "  Random sample of other candidates:\n",
      "    - MEDca (540 Needles) Derma Micro Needle Roller Black Titanium for Scar, Cellulite Treatment, Stret...\n",
      "    - Quality Bath Brush with Long Handle, Shower or Bath Brush long handled, Dry Skin Brushing Body Br...\n",
      "    - The Shave Well Company a TRULY FOG FREE Shower Shave Mirror. Truly fogless by design. Will not fa...\n"
     ]
    }
   ],
   "source": [
    "# Interactive Data Analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "print(\"üìä INTERACTIVE DATA ANALYSIS\\n\")\n",
    "\n",
    "# Load processed dataset for analysis\n",
    "with open(outputs_dir / 'beauty_dataset.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "\n",
    "print(\"üîç Session Length Distribution:\")\n",
    "session_lengths = [len(session['items']) for session in dataset.sessions]\n",
    "length_counts = Counter(session_lengths)\n",
    "\n",
    "# Show distribution\n",
    "print(f\"Min length: {min(session_lengths)}\")\n",
    "print(f\"Max length: {max(session_lengths)}\")\n",
    "print(f\"Average length: {np.mean(session_lengths):.2f}\")\n",
    "print(f\"Median length: {np.median(session_lengths):.2f}\")\n",
    "\n",
    "print(f\"\\nMost common session lengths:\")\n",
    "for length, count in length_counts.most_common(10):\n",
    "    print(f\"  {length} items: {count:,} sessions ({count/len(session_lengths)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üè∑Ô∏è Product Category Analysis:\")\n",
    "\n",
    "# Analyze product categories from names\n",
    "category_words = []\n",
    "for item_name in list(dataset.item_to_name.values())[:1000]:  # Sample for performance\n",
    "    words = item_name.lower().split()\n",
    "    # Look for beauty-related keywords\n",
    "    beauty_keywords = ['serum', 'cream', 'lotion', 'mascara', 'lipstick', 'foundation', \n",
    "                      'shampoo', 'conditioner', 'moisturizer', 'cleanser', 'oil']\n",
    "    for word in words:\n",
    "        if any(keyword in word for keyword in beauty_keywords):\n",
    "            category_words.append(word)\n",
    "\n",
    "if category_words:\n",
    "    category_counts = Counter(category_words)\n",
    "    print(f\"Most common beauty product types:\")\n",
    "    for category, count in category_counts.most_common(10):\n",
    "        print(f\"  {category}: {count} products\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ Recommendation Task Preview:\")\n",
    "\n",
    "# Show what a typical recommendation task looks like\n",
    "test_session = dataset.sessions[100]  # Pick a test session\n",
    "prompt_items, target = dataset.prepare_to_predict(test_session)\n",
    "candidates, target_idx = dataset.create_candidate_pool(test_session)\n",
    "\n",
    "print(f\"User session example:\")\n",
    "print(f\"  User ID: {test_session['user_id']}\")\n",
    "print(f\"  Total items in session: {len(test_session['items'])}\")\n",
    "print(f\"  Items for prediction context: {len(prompt_items)}\")\n",
    "print(f\"  Target item to predict: {target}\")\n",
    "\n",
    "print(f\"\\nüìù Context items (what user has purchased):\")\n",
    "for i, item_id in enumerate(prompt_items[:5]):  # Show first 5\n",
    "    item_name = dataset.get_item_name(item_id)\n",
    "    print(f\"  {i+1}. {item_name}\")\n",
    "if len(prompt_items) > 5:\n",
    "    print(f\"  ... and {len(prompt_items)-5} more items\")\n",
    "\n",
    "print(f\"\\nüéØ Prediction target:\")\n",
    "target_name = dataset.get_item_name(target)\n",
    "print(f\"  {target_name}\")\n",
    "\n",
    "print(f\"\\nüîÄ Candidate pool:\")\n",
    "print(f\"  Total candidates: {len(candidates)}\")\n",
    "print(f\"  Target is at position: {target_idx + 1}\")\n",
    "print(f\"  Random sample of other candidates:\")\n",
    "other_candidates = [c for i, c in enumerate(candidates) if i != target_idx][:3]\n",
    "for item_id in other_candidates:\n",
    "    item_name = dataset.get_item_name(item_id)\n",
    "    print(f\"    - {item_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558i0zboy2r",
   "metadata": {},
   "source": [
    "# Beauty Dataset Exploration Summary\n",
    "\n",
    "This notebook provides comprehensive exploration of the Amazon Beauty dataset:\n",
    "\n",
    "## üìÅ File Structure\n",
    "- **Input files**: `/agentic_recommender/data/inputs/`\n",
    "  - `reviews_Beauty.json`: Raw user-item interactions  \n",
    "  - `meta_Beauty.json`: Product metadata with titles and descriptions\n",
    "\n",
    "- **Output files**: `/agentic_recommender/data/outputs/`\n",
    "  - `beauty_dataset.pkl`: Complete processed dataset object\n",
    "  - `beauty_stats.json`: Dataset statistics\n",
    "  - `beauty_train/val/test.json`: Evaluation splits\n",
    "  - `beauty_evaluation_samples.json`: Ready-to-use evaluation tasks\n",
    "  - `beauty_item_to_name.json`: Item ID to name mappings\n",
    "\n",
    "## üéØ What You Can Do\n",
    "1. **Explore raw data**: See original Amazon review format and product metadata\n",
    "2. **Analyze processed data**: View statistics, splits, and data quality\n",
    "3. **Understand recommendation tasks**: See how sessions become prediction problems  \n",
    "4. **Interactive analysis**: Examine distributions and product categories\n",
    "\n",
    "## ‚úÖ Dataset Ready For\n",
    "- Sequential recommendation model training\n",
    "- Agentic recommendation workflows  \n",
    "- Evaluation and benchmarking\n",
    "- Product discovery and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e7f100",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0029ad42",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
