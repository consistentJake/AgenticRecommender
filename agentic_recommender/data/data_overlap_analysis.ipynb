{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overlap Analysis: Training vs Testing\n",
    "\n",
    "This notebook analyzes the overlap between training and testing data for:\n",
    "- Users (customer_id)\n",
    "- Cuisines (via vendor_id -> primary_cuisine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "from agentic_recommender.data.enriched_loader import DataConfig, EnrichedDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /home/zhenkai/anaconda3/lib/python3.12/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/zhenkai/.local/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/zhenkai/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/zhenkai/.local/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/zhenkai/.local/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/zhenkai/Downloads/data_se/data_se\n",
      "Files exist:\n",
      "  - Train orders: True\n",
      "  - Test orders: True\n",
      "  - Vendors: True\n",
      "  - Products: True\n"
     ]
    }
   ],
   "source": [
    "# Data paths\n",
    "DATA_DIR = Path(\"/home/zhenkai/Downloads/data_se/data_se\")\n",
    "\n",
    "# File names\n",
    "ORDERS_TRAIN = \"orders_se_train.txt\"\n",
    "ORDERS_TEST = \"orders_se_test.txt\"\n",
    "VENDORS_FILE = \"vendors_se.txt\"\n",
    "PRODUCTS_FILE = \"products_se.txt\"\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Files exist:\")\n",
    "print(f\"  - Train orders: {(DATA_DIR / ORDERS_TRAIN).exists()}\")\n",
    "print(f\"  - Test orders: {(DATA_DIR / ORDERS_TEST).exists()}\")\n",
    "print(f\"  - Vendors: {(DATA_DIR / VENDORS_FILE).exists()}\")\n",
    "print(f\"  - Products: {(DATA_DIR / PRODUCTS_FILE).exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data Using Project Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_merged_data(data_dir: Path, orders_file: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load and merge data using the project's EnrichedDataLoader.\n",
    "    \n",
    "    This reuses the same logic from workflow_runner.py -> enriched_loader.py\n",
    "    \"\"\"\n",
    "    config = DataConfig(\n",
    "        data_dir=data_dir,\n",
    "        orders_file=orders_file,\n",
    "        vendors_file=VENDORS_FILE,\n",
    "        products_file=PRODUCTS_FILE\n",
    "    )\n",
    "    loader = EnrichedDataLoader(config)\n",
    "    return loader.load_merged()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n",
      "Training data shape: (617196, 17)\n",
      "Columns: ['Unnamed: 0', 'customer_id', 'user_geohash', 'order_id', 'vendor_id', 'product_id', 'day_of_week', 'order_time', 'order_day', 'hour', 'day_num', 'day_name', 'cuisine', 'vendor_geohash', 'chain_id', 'product_name', 'unit_price']\n"
     ]
    }
   ],
   "source": [
    "# Load training data\n",
    "print(\"Loading training data...\")\n",
    "train_df = load_merged_data(DATA_DIR, ORDERS_TRAIN)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Columns: {list(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading testing data...\n",
      "Testing data shape: (139542, 17)\n",
      "Columns: ['Unnamed: 0', 'customer_id', 'user_geohash', 'order_id', 'vendor_id', 'product_id', 'day_of_week', 'order_time', 'order_day', 'hour', 'day_num', 'day_name', 'cuisine', 'vendor_geohash', 'chain_id', 'product_name', 'unit_price']\n"
     ]
    }
   ],
   "source": [
    "# Load testing data\n",
    "print(\"Loading testing data...\")\n",
    "test_df = load_merged_data(DATA_DIR, ORDERS_TEST)\n",
    "print(f\"Testing data shape: {test_df.shape}\")\n",
    "print(f\"Columns: {list(test_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>user_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_name</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>0</td>\n",
       "      <td>e1f3e4a4</td>\n",
       "      <td>9971ae2cd1ba</td>\n",
       "      <td>3</td>\n",
       "      <td>16:00:16</td>\n",
       "      <td>11 days</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Thu</td>\n",
       "      <td>italienskt</td>\n",
       "      <td>u6sc5</td>\n",
       "      <td>3ed908e5</td>\n",
       "      <td>Coca-Cola original taste 33 cl</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>0</td>\n",
       "      <td>e1f3e4a4</td>\n",
       "      <td>00734c4b351f</td>\n",
       "      <td>3</td>\n",
       "      <td>16:00:16</td>\n",
       "      <td>11 days</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>Thu</td>\n",
       "      <td>italienskt</td>\n",
       "      <td>u6sc5</td>\n",
       "      <td>3ed908e5</td>\n",
       "      <td>Parma</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>1</td>\n",
       "      <td>5d1b1300</td>\n",
       "      <td>9a2b00f39640</td>\n",
       "      <td>1</td>\n",
       "      <td>16:34:04</td>\n",
       "      <td>51 days</td>\n",
       "      <td>16</td>\n",
       "      <td>51</td>\n",
       "      <td>Tue</td>\n",
       "      <td>asiatiskt</td>\n",
       "      <td>u6sc6</td>\n",
       "      <td>f782a3fc</td>\n",
       "      <td>Pad Thai</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>3</td>\n",
       "      <td>5d1b1300</td>\n",
       "      <td>9a2b00f39640</td>\n",
       "      <td>3</td>\n",
       "      <td>16:23:14</td>\n",
       "      <td>53 days</td>\n",
       "      <td>16</td>\n",
       "      <td>53</td>\n",
       "      <td>Thu</td>\n",
       "      <td>asiatiskt</td>\n",
       "      <td>u6sc6</td>\n",
       "      <td>f782a3fc</td>\n",
       "      <td>Pad Thai</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>4</td>\n",
       "      <td>4790e97d</td>\n",
       "      <td>f6b685cff997</td>\n",
       "      <td>2</td>\n",
       "      <td>15:34:13</td>\n",
       "      <td>66 days</td>\n",
       "      <td>15</td>\n",
       "      <td>66</td>\n",
       "      <td>Wed</td>\n",
       "      <td>sushi</td>\n",
       "      <td>u6sc5</td>\n",
       "      <td></td>\n",
       "      <td>Coca-Cola original taste 33 cl</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 customer_id user_geohash  order_id vendor_id    product_id  \\\n",
       "0           0  90a4e98622        u6sc4         0  e1f3e4a4  9971ae2cd1ba   \n",
       "1           1  90a4e98622        u6sc4         0  e1f3e4a4  00734c4b351f   \n",
       "2           2  90a4e98622        u6sc4         1  5d1b1300  9a2b00f39640   \n",
       "3           4  90a4e98622        u6sc4         3  5d1b1300  9a2b00f39640   \n",
       "4           5  90a4e98622        u6sc4         4  4790e97d  f6b685cff997   \n",
       "\n",
       "   day_of_week order_time order_day  hour  day_num day_name     cuisine  \\\n",
       "0            3   16:00:16   11 days    16       11      Thu  italienskt   \n",
       "1            3   16:00:16   11 days    16       11      Thu  italienskt   \n",
       "2            1   16:34:04   51 days    16       51      Tue   asiatiskt   \n",
       "3            3   16:23:14   53 days    16       53      Thu   asiatiskt   \n",
       "4            2   15:34:13   66 days    15       66      Wed       sushi   \n",
       "\n",
       "  vendor_geohash  chain_id                    product_name  unit_price  \n",
       "0          u6sc5  3ed908e5  Coca-Cola original taste 33 cl       0.152  \n",
       "1          u6sc5  3ed908e5                           Parma       0.780  \n",
       "2          u6sc6  f782a3fc                        Pad Thai       0.640  \n",
       "3          u6sc6  f782a3fc                        Pad Thai       0.640  \n",
       "4          u6sc5            Coca-Cola original taste 33 cl       0.080  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sample data\n",
    "print(\"\\nTraining data sample:\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>user_geohash</th>\n",
       "      <th>order_id</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>order_time</th>\n",
       "      <th>order_day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_num</th>\n",
       "      <th>day_name</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>vendor_geohash</th>\n",
       "      <th>chain_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>unit_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>90a4e98622</td>\n",
       "      <td>u6sc4</td>\n",
       "      <td>2</td>\n",
       "      <td>5d1b1300</td>\n",
       "      <td>9a2b00f39640</td>\n",
       "      <td>6</td>\n",
       "      <td>14:39:12</td>\n",
       "      <td>84 days</td>\n",
       "      <td>14</td>\n",
       "      <td>84</td>\n",
       "      <td>Sun</td>\n",
       "      <td>asiatiskt</td>\n",
       "      <td>u6sc6</td>\n",
       "      <td>f782a3fc</td>\n",
       "      <td>Pad Thai</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>1c2b4598db</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td>11</td>\n",
       "      <td>262f6435</td>\n",
       "      <td>ae0b5cbf8dd1</td>\n",
       "      <td>6</td>\n",
       "      <td>17:10:04</td>\n",
       "      <td>84 days</td>\n",
       "      <td>17</td>\n",
       "      <td>84</td>\n",
       "      <td>Sun</td>\n",
       "      <td>pizza</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td></td>\n",
       "      <td>Standard</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1c2b4598db</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td>11</td>\n",
       "      <td>262f6435</td>\n",
       "      <td>674d25744130</td>\n",
       "      <td>6</td>\n",
       "      <td>17:10:04</td>\n",
       "      <td>84 days</td>\n",
       "      <td>17</td>\n",
       "      <td>84</td>\n",
       "      <td>Sun</td>\n",
       "      <td>pizza</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td></td>\n",
       "      <td>Pizzasallad</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>1c2b4598db</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td>11</td>\n",
       "      <td>262f6435</td>\n",
       "      <td>28da0a2a7fa3</td>\n",
       "      <td>6</td>\n",
       "      <td>17:10:04</td>\n",
       "      <td>84 days</td>\n",
       "      <td>17</td>\n",
       "      <td>84</td>\n",
       "      <td>Sun</td>\n",
       "      <td>pizza</td>\n",
       "      <td>u6sc9</td>\n",
       "      <td></td>\n",
       "      <td>Vitlökssås</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>894db839be</td>\n",
       "      <td>u6sc1</td>\n",
       "      <td>13</td>\n",
       "      <td>64a3af0f</td>\n",
       "      <td>de662e62862f</td>\n",
       "      <td>6</td>\n",
       "      <td>13:43:12</td>\n",
       "      <td>77 days</td>\n",
       "      <td>13</td>\n",
       "      <td>77</td>\n",
       "      <td>Sun</td>\n",
       "      <td>pizza</td>\n",
       "      <td>u6sc1</td>\n",
       "      <td></td>\n",
       "      <td>Kebabrulle</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 customer_id user_geohash  order_id vendor_id    product_id  \\\n",
       "0           3  90a4e98622        u6sc4         2  5d1b1300  9a2b00f39640   \n",
       "1          17  1c2b4598db        u6sc9        11  262f6435  ae0b5cbf8dd1   \n",
       "2          18  1c2b4598db        u6sc9        11  262f6435  674d25744130   \n",
       "3          19  1c2b4598db        u6sc9        11  262f6435  28da0a2a7fa3   \n",
       "4          23  894db839be        u6sc1        13  64a3af0f  de662e62862f   \n",
       "\n",
       "   day_of_week order_time order_day  hour  day_num day_name    cuisine  \\\n",
       "0            6   14:39:12   84 days    14       84      Sun  asiatiskt   \n",
       "1            6   17:10:04   84 days    17       84      Sun      pizza   \n",
       "2            6   17:10:04   84 days    17       84      Sun      pizza   \n",
       "3            6   17:10:04   84 days    17       84      Sun      pizza   \n",
       "4            6   13:43:12   77 days    13       77      Sun      pizza   \n",
       "\n",
       "  vendor_geohash  chain_id  product_name  unit_price  \n",
       "0          u6sc6  f782a3fc      Pad Thai       0.640  \n",
       "1          u6sc9                Standard       0.496  \n",
       "2          u6sc9             Pizzasallad       0.040  \n",
       "3          u6sc9             Vitlökssås        0.060  \n",
       "4          u6sc1            Kebabrulle         0.500  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Testing data sample:\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. User (Customer) Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "USER OVERLAP ANALYSIS\n",
      "============================================================\n",
      "\n",
      "Total unique users in training:  109,544\n",
      "Total unique users in testing:   46,264\n",
      "\n",
      "Users in BOTH train and test:    32,877\n",
      "Users ONLY in training:          76,667\n",
      "Users ONLY in testing:           13,387\n",
      "\n",
      "Overlap percentage (test users in train): 71.06%\n",
      "Overlap percentage (train users in test): 30.01%\n"
     ]
    }
   ],
   "source": [
    "# Extract unique users from each dataset\n",
    "train_users = set(train_df['customer_id'].unique())\n",
    "test_users = set(test_df['customer_id'].unique())\n",
    "\n",
    "# Calculate overlap\n",
    "common_users = train_users & test_users\n",
    "train_only_users = train_users - test_users\n",
    "test_only_users = test_users - train_users\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"USER OVERLAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal unique users in training:  {len(train_users):,}\")\n",
    "print(f\"Total unique users in testing:   {len(test_users):,}\")\n",
    "print(f\"\\nUsers in BOTH train and test:    {len(common_users):,}\")\n",
    "print(f\"Users ONLY in training:          {len(train_only_users):,}\")\n",
    "print(f\"Users ONLY in testing:           {len(test_only_users):,}\")\n",
    "print(f\"\\nOverlap percentage (test users in train): {len(common_users) / len(test_users) * 100:.2f}%\")\n",
    "print(f\"Overlap percentage (train users in test): {len(common_users) / len(train_users) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib_venn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Visualize user overlap\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib_venn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m venn2\n\u001b[32m      5\u001b[39m fig, ax = plt.subplots(figsize=(\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m))\n\u001b[32m      6\u001b[39m venn2(\n\u001b[32m      7\u001b[39m     subsets=(\u001b[38;5;28mlen\u001b[39m(train_only_users), \u001b[38;5;28mlen\u001b[39m(test_only_users), \u001b[38;5;28mlen\u001b[39m(common_users)),\n\u001b[32m      8\u001b[39m     set_labels=(\u001b[33m'\u001b[39m\u001b[33mTraining Users\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mTesting Users\u001b[39m\u001b[33m'\u001b[39m),\n\u001b[32m      9\u001b[39m     ax=ax\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib_venn'"
     ]
    }
   ],
   "source": [
    "# Visualize user overlap\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_venn import venn2\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "venn2(\n",
    "    subsets=(len(train_only_users), len(test_only_users), len(common_users)),\n",
    "    set_labels=('Training Users', 'Testing Users'),\n",
    "    ax=ax\n",
    ")\n",
    "plt.title('User Overlap between Training and Testing Data')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cuisine Overlap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique cuisines from each dataset\n",
    "train_cuisines = set(train_df['cuisine'].unique())\n",
    "test_cuisines = set(test_df['cuisine'].unique())\n",
    "\n",
    "# Calculate overlap\n",
    "common_cuisines = train_cuisines & test_cuisines\n",
    "train_only_cuisines = train_cuisines - test_cuisines\n",
    "test_only_cuisines = test_cuisines - train_cuisines\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"CUISINE OVERLAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal unique cuisines in training: {len(train_cuisines)}\")\n",
    "print(f\"Total unique cuisines in testing:  {len(test_cuisines)}\")\n",
    "print(f\"\\nCuisines in BOTH train and test:   {len(common_cuisines)}\")\n",
    "print(f\"Cuisines ONLY in training:         {len(train_only_cuisines)}\")\n",
    "print(f\"Cuisines ONLY in testing:          {len(test_only_cuisines)}\")\n",
    "print(f\"\\nOverlap percentage (test cuisines in train): {len(common_cuisines) / len(test_cuisines) * 100:.2f}%\")\n",
    "print(f\"Overlap percentage (train cuisines in test): {len(common_cuisines) / len(train_cuisines) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List cuisines\n",
    "print(\"\\nCuisines in BOTH train and test:\")\n",
    "for c in sorted(common_cuisines):\n",
    "    print(f\"  - {c}\")\n",
    "\n",
    "if train_only_cuisines:\n",
    "    print(\"\\nCuisines ONLY in training:\")\n",
    "    for c in sorted(train_only_cuisines):\n",
    "        print(f\"  - {c}\")\n",
    "\n",
    "if test_only_cuisines:\n",
    "    print(\"\\nCuisines ONLY in testing:\")\n",
    "    for c in sorted(test_only_cuisines):\n",
    "        print(f\"  - {c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cuisine overlap\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "venn2(\n",
    "    subsets=(len(train_only_cuisines), len(test_only_cuisines), len(common_cuisines)),\n",
    "    set_labels=('Training Cuisines', 'Testing Cuisines'),\n",
    "    ax=ax\n",
    ")\n",
    "plt.title('Cuisine Overlap between Training and Testing Data')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detailed Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuisine distribution comparison\n",
    "train_cuisine_counts = train_df.groupby('cuisine')['order_id'].nunique().sort_values(ascending=False)\n",
    "test_cuisine_counts = test_df.groupby('cuisine')['order_id'].nunique().sort_values(ascending=False)\n",
    "\n",
    "# Combine into a comparison dataframe\n",
    "cuisine_comparison = pd.DataFrame({\n",
    "    'train_orders': train_cuisine_counts,\n",
    "    'test_orders': test_cuisine_counts\n",
    "}).fillna(0).astype(int)\n",
    "cuisine_comparison['total'] = cuisine_comparison['train_orders'] + cuisine_comparison['test_orders']\n",
    "cuisine_comparison = cuisine_comparison.sort_values('total', ascending=False)\n",
    "\n",
    "print(\"Top 20 Cuisines by Total Orders:\")\n",
    "cuisine_comparison.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cuisine distribution\n",
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "top_cuisines = cuisine_comparison.head(15)\n",
    "x = range(len(top_cuisines))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar([i - width/2 for i in x], top_cuisines['train_orders'], width, label='Training', color='steelblue')\n",
    "bars2 = ax.bar([i + width/2 for i in x], top_cuisines['test_orders'], width, label='Testing', color='coral')\n",
    "\n",
    "ax.set_xlabel('Cuisine')\n",
    "ax.set_ylabel('Number of Orders')\n",
    "ax.set_title('Top 15 Cuisines: Training vs Testing Order Distribution')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(top_cuisines.index, rotation=45, ha='right')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User activity in training vs testing\n",
    "train_user_orders = train_df.groupby('customer_id')['order_id'].nunique()\n",
    "test_user_orders = test_df.groupby('customer_id')['order_id'].nunique()\n",
    "\n",
    "# For common users, compare activity\n",
    "common_user_stats = pd.DataFrame({\n",
    "    'train_orders': train_user_orders.reindex(common_users),\n",
    "    'test_orders': test_user_orders.reindex(common_users)\n",
    "}).dropna()\n",
    "\n",
    "print(\"\\nOrder Activity for Common Users:\")\n",
    "print(f\"  Mean train orders: {common_user_stats['train_orders'].mean():.2f}\")\n",
    "print(f\"  Mean test orders:  {common_user_stats['test_orders'].mean():.2f}\")\n",
    "print(f\"  Median train orders: {common_user_stats['train_orders'].median():.0f}\")\n",
    "print(f\"  Median test orders:  {common_user_stats['test_orders'].median():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vendor overlap analysis\n",
    "train_vendors = set(train_df['vendor_id'].unique())\n",
    "test_vendors = set(test_df['vendor_id'].unique())\n",
    "\n",
    "common_vendors = train_vendors & test_vendors\n",
    "train_only_vendors = train_vendors - test_vendors\n",
    "test_only_vendors = test_vendors - train_vendors\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"VENDOR OVERLAP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTotal unique vendors in training: {len(train_vendors):,}\")\n",
    "print(f\"Total unique vendors in testing:  {len(test_vendors):,}\")\n",
    "print(f\"\\nVendors in BOTH train and test:   {len(common_vendors):,}\")\n",
    "print(f\"Vendors ONLY in training:         {len(train_only_vendors):,}\")\n",
    "print(f\"Vendors ONLY in testing:          {len(test_only_vendors):,}\")\n",
    "print(f\"\\nOverlap percentage (test vendors in train): {len(common_vendors) / len(test_vendors) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "summary = pd.DataFrame({\n",
    "    'Training': [\n",
    "        len(train_df),\n",
    "        train_df['order_id'].nunique(),\n",
    "        len(train_users),\n",
    "        len(train_vendors),\n",
    "        len(train_cuisines),\n",
    "        train_df['product_id'].nunique()\n",
    "    ],\n",
    "    'Testing': [\n",
    "        len(test_df),\n",
    "        test_df['order_id'].nunique(),\n",
    "        len(test_users),\n",
    "        len(test_vendors),\n",
    "        len(test_cuisines),\n",
    "        test_df['product_id'].nunique()\n",
    "    ],\n",
    "    'Overlap': [\n",
    "        '-',\n",
    "        '-',\n",
    "        f\"{len(common_users):,} ({len(common_users)/len(test_users)*100:.1f}%)\",\n",
    "        f\"{len(common_vendors):,} ({len(common_vendors)/len(test_vendors)*100:.1f}%)\",\n",
    "        f\"{len(common_cuisines)} ({len(common_cuisines)/len(test_cuisines)*100:.1f}%)\",\n",
    "        '-'\n",
    "    ]\n",
    "}, index=['Total Rows', 'Unique Orders', 'Unique Users', 'Unique Vendors', 'Unique Cuisines', 'Unique Products'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommendations for Model Evaluation\n",
    "\n",
    "Based on the overlap analysis:\n",
    "\n",
    "1. **Cold-start users**: Users only in test data represent cold-start scenarios\n",
    "2. **Cuisine coverage**: High cuisine overlap means the model can generalize well\n",
    "3. **Vendor coverage**: Check if new vendors in test data affect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify cold-start scenarios\n",
    "cold_start_users = test_only_users\n",
    "warm_users = common_users\n",
    "\n",
    "# Test data breakdown\n",
    "test_cold_start_rows = test_df[test_df['customer_id'].isin(cold_start_users)]\n",
    "test_warm_rows = test_df[test_df['customer_id'].isin(warm_users)]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COLD-START ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nTest data from cold-start users: {len(test_cold_start_rows):,} rows ({len(test_cold_start_rows)/len(test_df)*100:.1f}%)\")\n",
    "print(f\"Test data from warm users:       {len(test_warm_rows):,} rows ({len(test_warm_rows)/len(test_df)*100:.1f}%)\")\n",
    "print(f\"\\nCold-start users: {len(cold_start_users):,}\")\n",
    "print(f\"Warm users:       {len(warm_users):,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
